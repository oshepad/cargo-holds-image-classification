


import os
import shutil

import random
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image

from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator, smart_resize

from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Input, Rescaling, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.metrics import Precision, Recall

from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score, RocCurveDisplay, auc








# Collect list of sources and image names
sources_path = '../data/sources/'
sources_directory = {}

for directory in os.listdir(sources_path):
    sources_directory[directory] = [i for i in os.listdir(sources_path + directory)]
    
# Create a dataframe to track image files
rows = []
for k, v in sources_directory.items():
    for value in v:
        rows.append([k, value])
images_df = pd.DataFrame(rows, columns=['source', 'original_name'])
images_df.head()


# Collect list of image types and image names
collected_path = '../data/collected'
raw_images = [i for i in os.listdir(collected_path)]

# Count of different types
image_types = []
for image in raw_images:
    file_types = image.rsplit('.', 1)[-1].lower()
    image_types.append(file_types)
image_types_count = pd.Series(image_types).value_counts()
print()
print(f'There are {len(raw_images)} images in the dataset. \nThey are distributed:\n {image_types_count}:')





# Update dataframe to indicate image class
clean_path = '../data/classified/clean/'
clean_images = [i for i in os.listdir(clean_path)]

dirty_path = '../data/classified/dirty/'
dirty_images = [i for i in os.listdir(dirty_path)]

not_used = []
for image in raw_images:
    if image not in clean_images and image not in dirty_images:
        not_used.append(image)

images_df['class'] = images_df['original_name'].apply(
    lambda image: 'clean' if image in clean_images 
    else ('dirty' if image in dirty_images else 'not_used'))

images_df['class'].value_counts()


# Checked not used files as not impactful for current intention
not_used





# Size of classes in the dataset
num_clean = len([i for i in os.listdir('../data/classified/clean/')])
num_dirty = len([i for i in os.listdir('../data/classified/dirty/')])
num_clean, num_dirty


# Pie chart with class distribution
fig, ax = plt.subplots()
ax.pie(x=[num_clean, num_dirty], labels=['Clean', 'Dirty'], colors=['lightblue', 'lightgreen'], autopct='%1.1f%%')
ax.set_title('Class Distribution')
plt.savefig('../assets/Class_Distribution.jpg')
plt.show();


# Review clean cargo hold image
clean1 = load_img('../data/classified/clean/47681173_2008763662504219_1873423245131120640_n.jpg')
clean2 = load_img('../data/classified/clean/48418327_2026951410685444_6927397904709582848_n.jpg')
clean1


# Review dirty cargo hold image
dirty1 = load_img('../data/classified/dirty/46706053_1983209351726317_6755771672986386432_n.jpg')
dirty2 = load_img('../data/classified/dirty/46491446_1983209548392964_3471892652591415296_n.jpg')
dirty1


# Comparing clean to dirty with similar color hold coatings

fig, axes = plt.subplots(2, 2, figsize=(12,12))

axes[0, 0].imshow(clean1)
axes[0, 0].set_title('Clean')
axes[0, 0].axis('off')

axes[0, 1].imshow(clean2)
axes[0, 1].set_title('Clean')
axes[0, 1].axis('off')

axes[1, 0].imshow(dirty1)
axes[1, 0].set_title('Dirty')
axes[1, 0].axis('off')

axes[1, 1].imshow(dirty2)
axes[1, 1].set_title('Dirty')
axes[1, 1].axis('off')

plt.show;


# different types of issues

cargoresidue = load_img('../data/classified/dirty/12c943_1ff40351da324d869a7f3b4c40d1b3e2~mv2.jpg')
cargoresidue2 = load_img('../data/classified/dirty/12c943_2fa04463d9254f2b8baf668e14de169a~mv2.jpg')
rustscale = load_img('../data/classified/dirty/66714988_2345934515453797_4846150941700784128_n.jpg')
tackypaint = load_img('../data/classified/dirty/12c943_e53efdefc0294acaa30e0a394f266436~mv2.jpg')
flakingpaint = load_img('../data/classified/dirty/12c943_efd8bd3332474e328fdbcef5cb7d2f46~mv2.jpg')
staining = load_img('../data/classified/dirty/46675044_1983208488393070_2248909549803143168_n.jpg')

fig, axes = plt.subplots(2, 3, figsize=(12,12))

axes[0, 0].imshow(cargoresidue)
axes[0, 0].set_title('Cement Cargo Residue')
axes[0, 0].axis('off')

axes[0, 1].imshow(cargoresidue2)
axes[0, 1].set_title('Petcoke Cargo Residue')
axes[0, 1].axis('off')

axes[0, 2].imshow(rustscale)
axes[0, 2].set_title('Rust Scale')
axes[0, 2].axis('off')

axes[1, 0].imshow(tackypaint)
axes[1, 0].set_title('Tacky Paint')
axes[1, 0].axis('off')

axes[1, 1].imshow(flakingpaint)
axes[1, 1].set_title('Flaking Paint')
axes[1, 1].axis('off')

axes[1, 2].imshow(staining)
axes[1, 2].set_title('Cargo Staining')
axes[1, 2].axis('off')

plt.show;





# gather image size ranges
clean_path = '../data/classified/clean/'
dirty_path = '../data/classified/dirty/'

clean_sizes = [load_img(os.path.join(clean_path, i)).size for i in os.listdir(clean_path)]
dirty_sizes = [load_img(os.path.join(dirty_path, i)).size for i in os.listdir(dirty_path)]

max(clean_sizes), min(clean_sizes), max(dirty_sizes), min(dirty_sizes)


# Review image size distribution
clean_sizes_dist = pd.Series(clean_sizes).value_counts()
dirty_sizes_dist = pd.Series(dirty_sizes).value_counts() 

size_dist = pd.concat([clean_sizes_dist, dirty_sizes_dist], axis=1)
size_dist.columns = ['Clean', 'Dirty']
size_dist.fillna(0, inplace=True)
size_dist['Total'] = size_dist['Clean'] + size_dist['Dirty']
size_dist_sorted = size_dist.sort_values('Total', ascending=False)

# plotting distributions
ax = size_dist_sorted[['Clean', 'Dirty']].plot(figsize=(10,10), kind='bar', stacked=True)
ax.set_title('Distribution of Image Sizes')
ax.set_ylabel('Count')
ax.set_xlabel('Number of Pixels (w x h)')
plt.show();


# Saving data collection and exploratuion to a csv
images_df.to_csv('../data/data_eda.csv', index=False)
