# imports
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
from PIL import Image

from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras.preprocessing.image import img_to_array, load_img, smart_resize, ImageDataGenerator

from tensorflow.keras.layers import Input, Rescaling, Dense, Dropout, Flatten, Conv2D, MaxPooling2D
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import EarlyStopping

from sklearn.model_selection import train_test_split
from sklearn.metrics import (balanced_accuracy_score, ConfusionMatrixDisplay, 
                            recall_score, precision_score, f1_score)
from skimage import io

# For reproducibility
np.random.seed(27)


# Convert webp files to jpg

def convert_webp_jpg(file_path):
    """Converting webp files to jpg.  JPG are well suited for CNNs due to size and quality""" 
    raw_dataset = os.listdir(file_path)
    for file in raw_dataset:
        if file.lower().endswith('.webp'):
            path = file_path + file
            with Image.open(path) as pic:
                pic = pic.convert('RGB')
                jpg = file.rsplit('.', 1)[0] + '.jpg'
                new_path = file_path + jpg
                pic.save(new_path, 'JPEG')


convert_webp_jpg('../data/01_raw/clean/')


convert_webp_jpg('../data/01_raw/dirty/')


train, test = image_dataset_from_directory(
    '../data/01_raw/',
    image_size=(128, 128),
    batch_size=4,
    label_mode='binary',
    seed=42,
    validation_split=0.1,
    subset='both'
)


# model for image classification
model = Sequential()
model.add(Input((128, 128, 3)))
model.add(Rescaling(1./255))

model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer='l2'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.50))

#model.add(Conv2D(128, (3, 3), activation='relu', kernel_regularizer='l2'))
#model.add(MaxPooling2D(pool_size=(2, 2)))
#model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.50))
model.add(Dense(1, activation='sigmoid'))

# compile model
model.compile(optimizer='adam', loss='bce', metrics=['accuracy'])

model.summary()


# fit model
model.fit(train, epochs=10, validation_data=test)








preds = np.round(model.predict(test), 2)


# check for a single image
tester = load_img('../data/02_classified/clean/47681173_2008763662504219_1873423245131120640_n.jpg')
test_image = img_to_array(tester)
test_image.shape


# resize image
test_image = smart_resize(test_image, (128, 128))
test_image.shape


# need to add a dimension as model is expecting a 4th dimension for the place in the batch
test_image = np.expand_dims(test_image, axis=0)
test_image.shape


model.predict(test_image)


test.class_names


tester





# data augmentation
datagen = ImageDataGenerator(
    brightness_range=(0.5, 1.5),
    rotation_range=45,
    width_shift_range=0.3,
    height_shift_range=0.3,
    shear_range=0.3,
    zoom_range=0.3,
    horizontal_flip=True,
    validation_split=0.1,
    fill_mode='constant'
)


x = io.imread('/content/47681173_2008763662504219_1873423245131120640_n.jpg')
x


x = x.reshape((1,) + x.shape)
x.shape


# https://www.youtube.com/watch?v=ccdssX4rIh8

i = 0
for batch in datagen.flow(x, batch_size=4,
                          save_to_dir='preview',
                          save_prefix='cargo',
                          save_format='jpeg'):
  i += 1
  if i > 20:
    break


# creating training data
train_generator = datagen.flow_from_directory(
    'cargo holds',
    target_size=(512, 512),
    batch_size=32,
    class_mode='binary',
    subset='training'
)


val_generator = datagen.flow_from_directory(
    'cargo holds',
    target_size=(512, 512),
    batch_size=32,
    class_mode='binary',
    subset='validation'
)


# fit model
model.fit(train_generator, epochs=10, validation_data=val_generator)



