


import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import random
import numpy as np
import pandas as pd
import shutil
import os
from PIL import Image

from sklearn.model_selection import train_test_split, GridSearchCV
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator, smart_resize

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Rescaling, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.metrics import Precision, Recall





clean_path = '../data/selective_data/train/clean/'
clean_images = [i for i in os.listdir(clean_path)]

dirty_path = '../data/selective_data/train/dirty/'
dirty_images = [i for i in os.listdir(dirty_path)]

len(clean_images), len(dirty_images)


# Holding back 25 and 34 random images from each class to serve as a test set.

# get ten random clean images
random.shuffle(clean_images)
test_clean_list = clean_images[:25]

# make a filepath
test_clean = []
for image in test_clean_list:
    test_clean.append(clean_path+image)

# move to test directory
for clean_image in test_clean:
    shutil.move(clean_image, '../data/selective_data/test/clean/')

# get ten random dirty images
random.shuffle(dirty_images)
test_dirty_list = dirty_images[:34]

# make a filepath
test_dirty = []
for image in test_dirty_list:
    test_dirty.append(dirty_path+image)

# move to test directory
for dirty_image in test_dirty:
    shutil.move(dirty_image, '../data/selective_data/test/dirty/')


num_clean = len([i for i in os.listdir('../data/selective_data/train/clean/')])
num_dirty = len([i for i in os.listdir('../data/selective_data/train/dirty/')])
num_clean, num_dirty


# Pie chart with class distribution
fig, ax = plt.subplots()
ax.pie(x=[num_clean, num_dirty], labels=['Clean', 'Dirty'], colors=['lightblue', 'lightgreen'], autopct='%1.1f%%')
ax.set_title('Class Distribution')
plt.show;





# create the image data generator to apply to the transformations to data
# the transformations are realistic as it relates to what could be seen
train_datagen = ImageDataGenerator(
    rescale = 1./255,
    brightness_range=(0.7, 1.3),
    rotation_range=45,
    width_shift_range=0.3,
    height_shift_range=0.3,
    shear_range=0.3,
    zoom_range=0.3,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split=0.1
)

model_target_size = (224, 224)
model_batch_size = 32

# Loading in image data
train_generator = train_datagen.flow_from_directory(
    '../data/selective_data/train/',
    target_size=model_target_size,
    batch_size=model_batch_size,
    class_mode='binary',
    subset='training',
    shuffle=True,
    seed=27,
)

validation_generator = train_datagen.flow_from_directory(
    '../data/selective_data/train/',
    target_size=model_target_size,
    batch_size=model_batch_size,
    class_mode='binary',
    subset='validation',
    shuffle=True,
    seed=27,
)


# model for image classification
model = Sequential()
model.add(Input((224, 224, 3)))

model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001)))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(BatchNormalization())
model.add(Dropout(0.2))

model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001)))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(BatchNormalization())
model.add(Dropout(0.2))

model.add(Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.001)))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(BatchNormalization())
model.add(Dropout(0.2))

model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.2))
model.add(Dense(1, activation='sigmoid'))

# compile model
optimizer = Adam(learning_rate=0.01)
model.compile(optimizer=optimizer, loss='bce', metrics=['accuracy', 'AUC', Precision(), Recall()])

model.summary()


# fit model
class_weights = {0: 0.9, 1: 1.1}
earlystopping = EarlyStopping(restore_best_weights=True, monitor='val_loss', min_delta=0, patience=15, verbose=1, mode='min')
model.fit(train_generator, epochs=20, validation_data=validation_generator, class_weight=class_weights, callbacks=[earlystopping])


model.save('../assets/saved_models/second_best_model')





def make_predictions(path):
    """Generate predictions for a dataset given its path.
    The dataset should be organized in a directory into subdirectories labelling the classes"""
    test_datagen = ImageDataGenerator(
        rescale=1./255 # This is a necessary preprocessing step
    )
    test_generator = test_datagen.flow_from_directory(
        path,
        target_size=model_target_size,
        batch_size=model_batch_size,
        class_mode=None,
        shuffle=False
    )
   
    predictions = model.predict(test_generator, verbose=1)
    predicted_class = np.argmax(predictions, axis=1)
    for image, pred_class in enumerate(predicted_class):
        print(f'Image {image+1} predicted as class: {pred_class}')

    return test_generator.classes
    


make_predictions('../data/selective_data/test/')


true_labels = test_generator.classes



