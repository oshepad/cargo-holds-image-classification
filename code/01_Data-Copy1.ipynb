{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0e91e94-cdc7-457d-9b87-abdc479391e8",
   "metadata": {},
   "source": [
    "# Cargo Holds: Clean or Dirty\n",
    "___\n",
    "\n",
    "#### Background\n",
    "\n",
    "Owning and operating a dry bulk vessel is challenging.  Earning a profit on any voyage is not a given even with careful calculations, knowledge, and a solid strategy.  Not only only are these profit margins getting thinner but they are absorbing more and more risk to earn them.  One of those risks is fixing a cargo that the vessel's cargo holds might not be ready for on time.  This leads to costly delays, tens of thousands of dollars in time, additional cleaning costs, and damage to a carriers reputation with a charterer.\n",
    "___\n",
    "\n",
    "#### Problem Statement\n",
    "\n",
    "Vessel operators have to decide a vessel's next cargo well ahead of knowing the condition her holds will be in when the vessel arrives to load the cargo.  The operator may have some knowledge to this problem, such as: the vessel's cargo histroy, overall condition of her holds coatings from the time of hire, and possibly the crew's experience and capability preparing the vessel's holds.  However, the determination of the suitability of her holds is left to an inspector's review of her holds before loading that the vessel operator does not have knowledge of in advance.\n",
    "___\n",
    "\n",
    "#### Solution\n",
    "\n",
    "That is why we have created this model.  With this deep learning CNN model, we have trained it on thousands of images of clean and dirty cargo holds against pictures of vessels that have passed inspection.  With this tool the vessel operator can quickly determine the likliehood, not a guarantee, that the vessel's holds will be accepted for the intended cargo.\n",
    "___\n",
    "\n",
    "#### Evidence\n",
    "\n",
    "This project lays out the steps and strategy taken to produce a model of distinguishing between a clean and dirty cargo hold.  The model has been measured for accuracy with the goal of reducing false positives.  In the problem of classifying a hold as clean or dirty, clean is a positive outcome and dirty is a negative outcome.  Therefore a false positive, an instance where the model incorrectly predicts the holds are clean, are limited. \n",
    "___\n",
    "\n",
    "#### Engage\n",
    "\n",
    "The model is only as good as the images it is provided.  If the images provided omit trouble spots or are not providing enough detail the results will be misleading.  The tool can be tried by submitting an image to the following link.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59259837-6507-468c-aabb-2a7362b76ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f1ea40-cc04-4be9-9c22-7011a82f5d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator, smart_resize\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Rescaling, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score, RocCurveDisplay, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35377e98-e7d4-47d7-96d1-57e5e0af2131",
   "metadata": {},
   "source": [
    "## Data\n",
    "___\n",
    "\n",
    "There were no publicly available datasets found online.  The dataset for this problem had to be collected.  From there it will be explored, pre-processed, and organized before being modeled.\n",
    "___\n",
    "\n",
    "![Data Directory](../assets/Data_Directory.jpg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3adcb55-51f3-4711-a656-3fdf65db10fe",
   "metadata": {},
   "source": [
    "___\n",
    "#### Data Collection\n",
    "\n",
    "The data was provided by Nippon Paint Marine, Three Ds Marine Inc, and Seachios Marine Services.  Three Ds Marine Inc is a cargo hold cleaning company based out of the Columbia River.  Seachios Marine Services is based out of Santos Brazil.  They were chosen, as not only do they do great work, as they are hired to prepare vessels for some of the more challenging cargo cleanliness standards to meet.  \n",
    "\n",
    "The Columbia River is one of the top grain exporteres in the world (behind the Mississippi River and Parana River) while Santos is the main port for grain exports in Brazil. Vessels need to be clean in order to transport grains. While this cleanliness standard is high, it is not the highest as some cargos need \"hospital clean\" cargo holds. These cargos are extremely sensitive to contamination, such as soda ash and alumina. The Columbia River is one of the largest exporters of soda ash which is used in the production of glass, detergents, batteries amongst other uses.  While Brazil exports large amounts of alumina used in the production of aluminum, ceramics, plastics, paints, and cosmetics. \n",
    "\n",
    "Nippon Marine Paint provided some images of freshly painted cargo holds.  Typically cargo holds that have been freshly painted in dry dock do not hire cleaning gangs.  These images are being added to capture this perspective.\n",
    "\n",
    "Due to their combination of quality and storage size, jpg images are preferred for this project.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7884df44-c117-436e-a817-2343096ae3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect list of image names\n",
    "sources_path = '../data/sources/'\n",
    "sources_directory = {}\n",
    "\n",
    "for directory in os.listdir(sources_path):\n",
    "    sources_directory[directory] = [i for i in os.listdir(sources_path + directory)]\n",
    "    \n",
    "sources_directory.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dcd46d-58fa-4be6-a8a5-1d60a0a3005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to track image files\n",
    "rows = []\n",
    "for k, v in sources_directory.items():\n",
    "    for value in v:\n",
    "        rows.append([k, value])\n",
    "sources_df = pd.DataFrame(rows, columns=['source', 'original_name'])\n",
    "sources_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bbc4b4-65e4-4bae-b2b5-fe6340d0d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect list of image names\n",
    "collected_path = '../data/collected'\n",
    "raw_images = [i for i in os.listdir(collected_path)]\n",
    "len(raw_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dab5c8-d1d1-4aaa-b57e-8237213f8b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of different types\n",
    "image_types = []\n",
    "for image in raw_images:\n",
    "    file_types = image.rsplit('.', 1)[-1].lower()\n",
    "    image_types.append(file_types)\n",
    "image_types_count = pd.Series(image_types).value_counts()\n",
    "image_types_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5134e150-b747-4cc1-85e6-da78a1e8fb52",
   "metadata": {},
   "source": [
    "___\n",
    "#### Data Classification\n",
    "Images were classified as dirty or clean after visual review.  To track the same, they were updated on the sources_df along with a new name.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8d0d45-0d65-45de-beb8-03fae2e0ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update dataframe to indicate image class\n",
    "clean_path = '../data/classified/clean/'\n",
    "clean_images = [i for i in os.listdir(clean_path)]\n",
    "\n",
    "dirty_path = '../data/classified/dirty/'\n",
    "dirty_images = [i for i in os.listdir(dirty_path)]\n",
    "\n",
    "not_used = []\n",
    "for image in raw_images:\n",
    "    if image not in clean_images and image not in dirty_images:\n",
    "        not_used.append(image)\n",
    "\n",
    "sources_df['class'] = sources_df['original_name'].apply(\n",
    "    lambda image: 'clean' if image in clean_images \n",
    "    else ('dirty' if image in dirty_images else 'not_used'))\n",
    "\n",
    "sources_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab753df-12b0-4bc6-af63-74176ad655ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new name, not renaming\n",
    "sources_df['new_name'] = sources_df['class'] + '_' + sources_df.index.astype(str)\n",
    "sources_df.sort_values(by='source', inplace=True)\n",
    "sources_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72895d6a-48f5-4379-a691-6e5b6027b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checked not used files as not impactful for current intention\n",
    "not_used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0a93f6-eb75-4175-b9c1-46f1d3879ff8",
   "metadata": {},
   "source": [
    "___\n",
    "#### Data Exploration\n",
    "\n",
    "The initial dataset contained 560 images.  It was straightforward to classify the holds as clean or dirty working with a dataset of this size.  It was also quickly noticeable that this dataset is imbalanced, with 94 clean cargo holds and 466 dirty cargo holds.  In the real world, this data should be perfectly balanced as a cargo hold is either clean or dirty for the purposes of this problem.  The working process for determining cargo hold cleanlieness would start with dirty cargo holds and end with clean holds.\n",
    "\n",
    "From this initial classification of the dataset, the images will be explored further to get a better understanding viusally of the data, the types of issues that render a cargo hold dirty, and the distribution of the size of images.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe0307e-7a3e-46f9-b118-43e32eddd2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of classes in the dataset\n",
    "num_clean = len([i for i in os.listdir('../data/classified/clean/')])\n",
    "num_dirty = len([i for i in os.listdir('../data/classified/dirty/')])\n",
    "num_clean, num_dirty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bfd361-71ca-4bc8-b089-ff3c61770df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart with class distribution\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(x=[num_clean, num_dirty], labels=['Clean', 'Dirty'], colors=['lightblue', 'lightgreen'], autopct='%1.1f%%')\n",
    "ax.set_title('Class Distribution')\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acc1224-8533-44fc-8adb-7764d11d4327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review clean cargo hold image\n",
    "clean1 = load_img('../data/classified/clean/47681173_2008763662504219_1873423245131120640_n.jpg')\n",
    "clean2 = load_img('../data/classified/clean/48418327_2026951410685444_6927397904709582848_n.jpg')\n",
    "clean1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2473d3d1-c2e9-4749-8f1c-faf8c7cfc167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review dirty cargo hold image\n",
    "dirty1 = load_img('../data/classified/dirty/46706053_1983209351726317_6755771672986386432_n.jpg')\n",
    "dirty2 = load_img('../data/classified/dirty/46491446_1983209548392964_3471892652591415296_n.jpg')\n",
    "dirty1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318626d7-8511-4ef9-8dfe-ab5394a3b054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing clean to dirty with similar color hold coatings\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12,12))\n",
    "\n",
    "axes[0, 0].imshow(clean1)\n",
    "axes[0, 0].set_title('Clean')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(clean2)\n",
    "axes[0, 1].set_title('Clean')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(dirty1)\n",
    "axes[1, 0].set_title('Dirty')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(dirty2)\n",
    "axes[1, 1].set_title('Dirty')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3a9ad6-114d-4844-b28b-350811777122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different types of issues\n",
    "\n",
    "cargoresidue = load_img('../data/classified/dirty/12c943_1ff40351da324d869a7f3b4c40d1b3e2~mv2.jpg')\n",
    "cargoresidue2 = load_img('../data/classified/dirty/12c943_2fa04463d9254f2b8baf668e14de169a~mv2.jpg')\n",
    "rustscale = load_img('../data/classified/dirty/66714988_2345934515453797_4846150941700784128_n.jpg')\n",
    "tackypaint = load_img('../data/classified/dirty/12c943_e53efdefc0294acaa30e0a394f266436~mv2.jpg')\n",
    "flakingpaint = load_img('../data/classified/dirty/12c943_efd8bd3332474e328fdbcef5cb7d2f46~mv2.jpg')\n",
    "staining = load_img('../data/classified/dirty/46675044_1983208488393070_2248909549803143168_n.jpg')\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12,12))\n",
    "\n",
    "axes[0, 0].imshow(cargoresidue)\n",
    "axes[0, 0].set_title('Cement Cargo Residue')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(cargoresidue2)\n",
    "axes[0, 1].set_title('Petcoke Cargo Residue')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(rustscale)\n",
    "axes[0, 2].set_title('Rust Scale')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(tackypaint)\n",
    "axes[1, 0].set_title('Tacky Paint')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(flakingpaint)\n",
    "axes[1, 1].set_title('Flaking Paint')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].imshow(staining)\n",
    "axes[1, 2].set_title('Cargo Staining')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3290bc-137e-41af-82ff-31976f15f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather image size ranges\n",
    "clean_path = '../data/classified/clean/'\n",
    "dirty_path = '../data/classified/dirty/'\n",
    "\n",
    "clean_sizes = [load_img(os.path.join(clean_path, i)).size for i in os.listdir(clean_path)]\n",
    "dirty_sizes = [load_img(os.path.join(dirty_path, i)).size for i in os.listdir(dirty_path)]\n",
    "\n",
    "max(clean_sizes), min(clean_sizes), max(dirty_sizes), min(dirty_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1034da-4aa3-495e-a4c2-5943aec20baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review image size distribution\n",
    "clean_sizes_dist = pd.Series(clean_sizes).value_counts()\n",
    "dirty_sizes_dist = pd.Series(dirty_sizes).value_counts() \n",
    "\n",
    "size_dist = pd.concat([clean_sizes_dist, dirty_sizes_dist], axis=1)\n",
    "size_dist.columns = ['Clean', 'Dirty']\n",
    "size_dist.fillna(0, inplace=True)\n",
    "size_dist['Total'] = size_dist['Clean'] + size_dist['Dirty']\n",
    "size_dist_sorted = size_dist.sort_values('Total', ascending=False)\n",
    "\n",
    "# plotting distributions\n",
    "ax = size_dist_sorted[['Clean', 'Dirty']].plot(figsize=(10,10), kind='bar', stacked=True)\n",
    "ax.set_title('Distribution of Image Sizes')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xlabel('Number of Pixels (w x h)')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d133d7e-ac3a-4f3e-9882-c869bafe61ee",
   "metadata": {},
   "source": [
    "___\n",
    "#### Data Pre-processing\n",
    "\n",
    "This project is working with an imbalanced and small dataset.  There are some preprocessing steps to take to improve the model performance.  These steps can be tailored in the future as the dataset size increases.\n",
    "\n",
    "* Splitting\n",
    "* Image Augmentation\n",
    "* Image Generator\n",
    "\n",
    "Before creating synthetic images to balance out the dataset, we will hold back 10% for a test set of unaltered images.  This will be based on 10% of the dirty images, the target number for balancing the minority dataset.  This is a relatively large set, 20% of the clean images, but this will eliminate overstating or understating the evaluation of the model.  In time this will not be as significant as te dataset is natually balanced out.\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade8fae9-8cbb-451e-807f-602d7b89cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of images to hold back for test set\n",
    "test_target = round(len(dirty_images) / 10, 0)\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d204381-efa0-436e-aed1-20aaddb4ed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holding 10 percent images from each class to serve as a test set.\n",
    "\n",
    "# get ten random clean images\n",
    "random.shuffle(clean_images)\n",
    "test_clean_list = clean_images[:55]\n",
    "\n",
    "# make a filepath\n",
    "test_clean = []\n",
    "for image in test_clean_list:\n",
    "    test_clean.append(clean_path+image)\n",
    "\n",
    "# move to test directory\n",
    "for clean_image in test_clean:\n",
    "    shutil.move(clean_image, '../data/test/clean/')\n",
    "\n",
    "# get ten random dirty images\n",
    "random.shuffle(dirty_images)\n",
    "test_dirty_list = dirty_images[:55]\n",
    "\n",
    "# make a filepath\n",
    "test_dirty = []\n",
    "for image in test_dirty_list:\n",
    "    test_dirty.append(dirty_path+image)\n",
    "\n",
    "# move to test directory\n",
    "for dirty_image in test_dirty:\n",
    "    shutil.move(dirty_image, '../data/test/dirty/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7da87a-d905-4e7a-95ea-94f5d91f03fd",
   "metadata": {},
   "source": [
    "___\n",
    "#### Image Augmentation\n",
    "Synthetic images of the clean cargo hold class will be generated to address the class imbalance.  Oversampling the minority class could also work, but synthetic generation is preferred to avoid creating a bias by relying on multiple samples of the same image.  Synthetic images create more variety with synthetic creation, flips, crops, etc to avoid introducing bias to repeated samples.\n",
    "\n",
    "It should be noted that this approach is not ideal.  The size of this dataset is insufficient to provide confidence in the model's performance.  Only after obtaining more data (roughly 1000 images per class) should the model be considered for production, without creating synthetic images.\n",
    "\n",
    "In the real world, this dataset should be equally balanced. The vessel should provide pictures of dirty holds and eventually clean holds. A vessel's cargo holds are either dirty or clean.ved.\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4734436-d911-471f-ada8-d74d92ad44dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating more images from original dataset\n",
    "balance_datagen = ImageDataGenerator(\n",
    "    brightness_range=(0.5, 1.5),\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=[0.4, 0.6],\n",
    "    channel_shift_range=100,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7dc91e-ef50-46b9-8538-90c8a0049d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetics(image_list, target, destination_path):\n",
    "    \"\"\"Create more images from a given image list and save to destination\"\"\"\n",
    "    # determine how many images to generate per image\n",
    "    generate_per_image = target / (len(image_list))\n",
    "\n",
    "    # loop through image list and generate synthetic images\n",
    "    for image in image_list:\n",
    "        try:\n",
    "            x = load_img(image)\n",
    "            x = img_to_array(x)\n",
    "            x = x.reshape((1,) + x.shape)\n",
    "            i = 0\n",
    "            for batch in balance_datagen.flow(x, batch_size=1, save_to_dir=destination_path, save_prefix='aug', save_format='jpg'):\n",
    "                i += 1\n",
    "                if i > generate_per_image:\n",
    "                    break  \n",
    "        except FileNotFoundError:\n",
    "            print(f'{image} was not found as it was moved to the Test dataset. Skipping ...')\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ef2ca6-3983-4003-8237-f13798c8b568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating more clean images\n",
    "\n",
    "#clean_class_images = [clean_path + file for file in clean_images]\n",
    "#clean_augmented = '../data/augmented/clean/'\n",
    "#clean_target = 375\n",
    "#create_synthetics(clean_class_images, clean_target, clean_augmented)\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b21a11-a340-46e1-aa5e-b60b6e533d9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating more dirty images so model sees some orientation variation\n",
    "\n",
    "#dirty_class_images = [dirty_path + file for file in dirty_images]\n",
    "#dirty_augmented = '../data/augmented/dirty/'\n",
    "#dirty_target = 200\n",
    "#create_synthetics(dirty_class_images, dirty_target, dirty_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2164c6f9-6ed8-49ea-8649-dfcd65de7340",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_aug_clean = len([i for i in os.listdir('../data/augmented/clean/')])\n",
    "num_aug_dirty = len([i for i in os.listdir('../data/augmented/dirty/')])\n",
    "num_aug_clean, num_aug_dirty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e2313a-40e6-4e9c-a662-7dc34b0a4a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart with class distribution\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(x=[num_aug_clean, num_aug_dirty], labels=['Clean', 'Dirty'], colors=['lightblue', 'lightgreen'], autopct='%1.1f%%')\n",
    "ax.set_title('Class Distribution')\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e766b4-399b-4ff3-8b55-5ffd92281a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the remaining images into training and validation datasets\n",
    "\n",
    "# training & validation clean\n",
    "try:\n",
    "    augmented_clean_path = '../data/augmented/clean/'\n",
    "    augmented_clean_images = [i for i in os.listdir(augmented_clean_path)]\n",
    "    random.shuffle(augmented_clean_images)\n",
    "    \n",
    "    train_clean = []\n",
    "    augmented_clean_train = augmented_clean_images[:520]\n",
    "    for act_image in augmented_clean_train:\n",
    "        train_clean.append(os.path.join(augmented_clean_path + act_image))\n",
    "    for train_clean_image in train_clean:\n",
    "        shutil.move(train_clean_image, '../data/train/clean/')\n",
    "        \n",
    "    val_clean = []\n",
    "    augmented_clean_val = augmented_clean_images[520:]\n",
    "    for acv_image in augmented_clean_val:\n",
    "        val_clean.append(os.path.join(augmented_clean_path + acv_image))\n",
    "    for val_clean_image in val_clean:\n",
    "        shutil.move(val_clean_image, '../data/validate/clean/')\n",
    "        \n",
    "    #training & validation dirty\n",
    "    augmented_dirty_path = '../data/augmented/dirty/'\n",
    "    augmented_dirty_images = [i for i in os.listdir(augmented_dirty_path)]\n",
    "    random.shuffle(augmented_dirty_images)\n",
    "    \n",
    "    train_dirty = []\n",
    "    augmented_dirty_train = augmented_dirty_images[:520]\n",
    "    for adt_image in augmented_dirty_train:\n",
    "        train_dirty.append(os.path.join(augmented_dirty_path + adt_image))\n",
    "    for train_dirty_image in train_dirty:\n",
    "        shutil.move(train_dirty_image, '../data/train/dirty/')\n",
    "    \n",
    "    val_dirty = []\n",
    "    augmented_dirty_val = augmented_dirty_images[520:]\n",
    "    for adv_image in augmented_dirty_val:\n",
    "        val_dirty.append(os.path.join(augmented_dirty_path + adv_image))\n",
    "    for val_dirty_image in val_dirty:\n",
    "        shutil.move(val_dirty_image, '../data/validate/dirty/')\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f'Image was not found {e} as it was moved to the Test dataset. Skipping ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2f76e8-da8b-4b8b-ba69-bd5235e640ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_clean = len([i for i in os.listdir('../data/train/clean/')])\n",
    "num_train_dirty = len([i for i in os.listdir('../data/train/dirty/')])\n",
    "\n",
    "num_val_clean = len([i for i in os.listdir('../data/validate/clean/')])\n",
    "num_val_dirty = len([i for i in os.listdir('../data/validate/dirty/')])\n",
    "\n",
    "num_test_clean = len([i for i in os.listdir('../data/test/clean/')])\n",
    "num_test_dirty = len([i for i in os.listdir('../data/test/dirty/')])\n",
    "\n",
    "num_train_clean, num_train_dirty, num_val_clean, num_val_dirty, num_test_clean, num_test_dirty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7fc8116f-8713-44a7-a3c8-92886b219240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>original_name</th>\n",
       "      <th>source</th>\n",
       "      <th>class</th>\n",
       "      <th>new_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_clean_images</td>\n",
       "      <td>046c7aff-205a-46c5-8412-6b6fac84fb00.jpg</td>\n",
       "      <td>Seachios</td>\n",
       "      <td>clean</td>\n",
       "      <td>clean_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_clean_images</td>\n",
       "      <td>0a9ce194-f3f2-4efe-9621-c0df37e23e77.jpg</td>\n",
       "      <td>Seachios</td>\n",
       "      <td>clean</td>\n",
       "      <td>clean_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_clean_images</td>\n",
       "      <td>0b80c8d6-b7ed-4d79-a706-998916e0a382.jpg</td>\n",
       "      <td>Seachios</td>\n",
       "      <td>not_used</td>\n",
       "      <td>not_used_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_clean_images</td>\n",
       "      <td>1000052030.jpg</td>\n",
       "      <td>Seachios</td>\n",
       "      <td>clean</td>\n",
       "      <td>clean_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_clean_images</td>\n",
       "      <td>1000052031.jpg</td>\n",
       "      <td>Seachios</td>\n",
       "      <td>clean</td>\n",
       "      <td>clean_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>test_dirty_images</td>\n",
       "      <td>IMG_2141.jpg</td>\n",
       "      <td>Three Ds Marine</td>\n",
       "      <td>not_used</td>\n",
       "      <td>not_used_793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>test_dirty_images</td>\n",
       "      <td>IMG_2142.jpg</td>\n",
       "      <td>Three Ds Marine</td>\n",
       "      <td>not_used</td>\n",
       "      <td>not_used_794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>test_dirty_images</td>\n",
       "      <td>IMG_2179.jpg</td>\n",
       "      <td>Three Ds Marine</td>\n",
       "      <td>not_used</td>\n",
       "      <td>not_used_806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>test_dirty_images</td>\n",
       "      <td>IMG_2182.jpg</td>\n",
       "      <td>Three Ds Marine</td>\n",
       "      <td>not_used</td>\n",
       "      <td>not_used_808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>test_dirty_images</td>\n",
       "      <td>IMG_2223.jpg</td>\n",
       "      <td>Three Ds Marine</td>\n",
       "      <td>not_used</td>\n",
       "      <td>not_used_812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   split                             original_name  \\\n",
       "0     train_clean_images  046c7aff-205a-46c5-8412-6b6fac84fb00.jpg   \n",
       "1     train_clean_images  0a9ce194-f3f2-4efe-9621-c0df37e23e77.jpg   \n",
       "2     train_clean_images  0b80c8d6-b7ed-4d79-a706-998916e0a382.jpg   \n",
       "3     train_clean_images                            1000052030.jpg   \n",
       "4     train_clean_images                            1000052031.jpg   \n",
       "...                  ...                                       ...   \n",
       "1255   test_dirty_images                              IMG_2141.jpg   \n",
       "1256   test_dirty_images                              IMG_2142.jpg   \n",
       "1257   test_dirty_images                              IMG_2179.jpg   \n",
       "1258   test_dirty_images                              IMG_2182.jpg   \n",
       "1259   test_dirty_images                              IMG_2223.jpg   \n",
       "\n",
       "               source     class      new_name  \n",
       "0            Seachios     clean       clean_6  \n",
       "1            Seachios     clean       clean_9  \n",
       "2            Seachios  not_used   not_used_11  \n",
       "3            Seachios     clean      clean_13  \n",
       "4            Seachios     clean      clean_14  \n",
       "...               ...       ...           ...  \n",
       "1255  Three Ds Marine  not_used  not_used_793  \n",
       "1256  Three Ds Marine  not_used  not_used_794  \n",
       "1257  Three Ds Marine  not_used  not_used_806  \n",
       "1258  Three Ds Marine  not_used  not_used_808  \n",
       "1259  Three Ds Marine  not_used  not_used_812  \n",
       "\n",
       "[1260 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update dataframe to indicate train/validate/test split\n",
    "\n",
    "# Create lists of where each image was assigned\n",
    "train_clean_path = '../data/train/clean'\n",
    "train_clean_images = [i for i in os.listdir(train_clean_path)]\n",
    "train_dirty_path = '../data/train/dirty'\n",
    "train_dirty_images = [i for i in os.listdir(train_dirty_path)]\n",
    "validate_clean_path = '../data/validate/clean'\n",
    "validate_clean_images = [i for i in os.listdir(validate_clean_path)]\n",
    "validate_dirty_path = '../data/validate/dirty'\n",
    "validate_dirty_images = [i for i in os.listdir(validate_dirty_path)]\n",
    "test_clean_path = '../data/test/clean'\n",
    "test_clean_images = [i for i in os.listdir(test_clean_path)]\n",
    "test_dirty_path = '../data/test/dirty'\n",
    "test_dirty_images = [i for i in os.listdir(test_dirty_path)]\n",
    "\n",
    "\n",
    "# store them in a dictionary and convert to a dataframe\n",
    "split_dict = {\n",
    "    'split': \n",
    "    ['train_clean_images'] * len(train_clean_images) + \n",
    "    ['train_dirty_images'] * len(train_dirty_images) +\n",
    "    ['validate_clean_images'] * len(validate_clean_images) + \n",
    "    ['validate_dirty_images'] * len(validate_dirty_images) +\n",
    "    ['test_clean_images'] * len(test_clean_images) + \n",
    "    ['test_dirty_images'] * len(test_dirty_images),\n",
    "    'original_name': \n",
    "    train_clean_images + \n",
    "    train_dirty_images + \n",
    "    validate_clean_images + \n",
    "    validate_dirty_images +\n",
    "    test_clean_images + \n",
    "    test_dirty_images\n",
    "}\n",
    "\n",
    "split_df = pd.DataFrame(split_dict)\n",
    "split_df = pd.merge(split_df, sources_df, on='original_name', how='left')\n",
    "split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf6b2d2-4ccb-411d-b89c-d4545a631a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86213b4-e349-4d5b-8b70-73b8b7b2ba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store them in a dictionary and convert to a dataframe\n",
    "split_dict = {\n",
    "    'train_clean': train_clean_images,\n",
    "    'train_dirty': train_dirty_images,\n",
    "    'validate_clean': validate_clean_images,\n",
    "    'validate_dirty': validate_dirty_images,\n",
    "    'test_clean': test_clean_images,\n",
    "    'test_dirty': test_dirty_images,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e8b65d-0717-40af-bdf1-3a1fbf0e3078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a5e4fd-1cff-4d0c-a54c-29375d8d9d87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916331e3-3549-4788-a733-1302f1fde724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update dataframe to indicate train/validate/test split\n",
    "train_clean_path = '../data/train/clean'\n",
    "train_clean_images = [i for i in os.listdir(clean_path)]\n",
    "\n",
    "dirty_path = '../data/classified/dirty/'\n",
    "dirty_images = [i for i in os.listdir(dirty_path)]\n",
    "\n",
    "not_used = []\n",
    "for image in raw_images:\n",
    "    if image not in clean_images and image not in dirty_images:\n",
    "        not_used.append(image)\n",
    "\n",
    "sources_df['class'] = sources_df['original_name'].apply(\n",
    "    lambda image: 'clean' if image in clean_images \n",
    "    else ('dirty' if image in dirty_images else 'not_used'))\n",
    "\n",
    "sources_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6193ff-d642-48af-9afe-9b07d034ad25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2e06d1-7cc7-41e1-ae34-b343f24da553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new name, not renaming\n",
    "sources_df['split'] = sources_df['class'] + '_' + sources_df.index.astype(str)\n",
    "sources_df.sort_values(by='source', inplace=True)\n",
    "sources_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8575af6b-801f-4779-8c05-d5d7239d6cdb",
   "metadata": {},
   "source": [
    "___\n",
    "#### Modeling\n",
    "\n",
    "Now that synthetic data has been created to balance the imbalanced datasets, the model can be constructed and fit.  The dataset is still small, so to increase the size of the training set, the training data will be augmented on the fly during training using tensorflow ImageDataGenerator.  The rotations there will be kept modest as a significant portion of synthetic data was already generated.  Additionally the model will be regularized and normalized (by rescaling, dropout, batchnormalization, l2, learning rate, and early stopping )\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5915a2d1-3f02-4eb5-b70c-1f83410776bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the image data generator to apply to the transformations to data\n",
    "# the transformations are realistic as it relates to what could be seen\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    brightness_range=(0.8, 1.2),\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    ")\n",
    "\n",
    "validate_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    ")\n",
    "\n",
    "# Loading in image data\n",
    "model_target_size = (224, 224)\n",
    "model_batch_size = 32\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '../data/train/',\n",
    "    target_size=model_target_size,\n",
    "    batch_size=model_batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True,\n",
    "    seed=27,\n",
    ")\n",
    "\n",
    "validation_generator = validate_datagen.flow_from_directory(\n",
    "    '../data/validate/',\n",
    "    target_size=model_target_size,\n",
    "    batch_size=model_batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True,\n",
    "    seed=27,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506cbb0d-51e5-48c8-b30a-c377711a3db4",
   "metadata": {},
   "source": [
    "# model for image classification\n",
    "model = Sequential()\n",
    "model.add(Input((224, 224, 3)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.0001)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile model\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='bce', metrics=['accuracy', 'AUC', Precision(), Recall()])\n",
    "\n",
    "# architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec12ce2d-9316-41ae-9f72-f399f79eaa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model for image classification\n",
    "model = Sequential()\n",
    "model.add(Input((224, 224, 3)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.0001)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile model\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='bce', metrics=['accuracy', 'AUC', Precision(), Recall()])\n",
    "\n",
    "# architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f38fad-d1fb-41a6-9c75-acf6ad57fb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add callbacks\n",
    "checkpoint_path='../assets/saved_models/'\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1, save_weights_only=False)\n",
    "earlystopping = EarlyStopping(restore_best_weights=True, monitor='val_accuracy', min_delta=0, patience=15, verbose=1, mode='auto')\n",
    "\n",
    "# fit model\n",
    "history = model.fit(train_generator, epochs=25, validation_data=validation_generator, callbacks=[earlystopping, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88dd485-6e44-4a34-9da5-3f85b15eb2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the training and validation metrics over epochs\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(history.history['loss'], label='Training Loss', )\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.plot(history.history['recall_16'], label='Training Recall')\n",
    "plt.plot(history.history['val_recall_16'], label='Validation Recall')\n",
    "plt.title('Evaluation over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Metrics')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a548cbfc-ddbc-4896-b130-20cbc7fa94ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../assets/saved_models/good_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2e263e-bf56-4a4a-9a04-647611c3926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model for comparison\n",
    "best_model = load_model('../assets/saved_models/best_model/saved_model.pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe79646-f978-49f6-9cd5-c94ccd82bd90",
   "metadata": {},
   "source": [
    "___\n",
    "#### Predictions\n",
    "Let's see how the model does on the test set.  The test set will need to be resaled.\n",
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1b600-ad38-4abc-9bb0-ab2440c1fb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed the test dataset to the model to generate predictions\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255 # This is a necessary preprocessing step\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    '../data/test/',\n",
    "    target_size=model_target_size,\n",
    "    batch_size=model_batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9438e9-375b-458c-aefa-e5355292c9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "predictions = model.predict(test_generator, verbose=1)\n",
    "predicted_class = (predictions > 0.5).astype(int)\n",
    "class_labels = test_generator.classes\n",
    "image_names = test_generator.filenames\n",
    "\n",
    "# print image name and prediction\n",
    "for image, pred_class in enumerate(predicted_class):\n",
    "    print(f'Image {image_names[image]} predicted as class: {pred_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0a348a-19f8-4e41-b73a-d74be488fb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation metrics\n",
    "precision = precision_score(class_labels, predicted_class)\n",
    "recall = recall_score(class_labels, predicted_class)\n",
    "f1_result = f1_score(class_labels, predicted_class)\n",
    "confusing_matrix = confusion_matrix(class_labels, predicted_class)\n",
    "\n",
    "print(f'Precision score: {round(precision, 2)}.')\n",
    "print(f'Recall score: {round(recall, 2)}.')\n",
    "print(f'F1 score: {round(f1_result, 2)}.')\n",
    "\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrix=confusing_matrix, display_labels=test_generator.class_indices)\n",
    "cmd.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd910e3-58f1-4e6b-b1e0-3d3fabadb3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the ROC Curve - will help us see how well the model is defining classes\n",
    "fpr, tpr, thresholds = roc_curve(class_labels, predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)\n",
    "roc_display.plot()\n",
    "plt.legend()\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ef8034-d7ad-4449-a194-e09566576b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the roc_auc_score\n",
    "roc_auc_score = round(roc_auc_score(class_labels, predictions), 4)\n",
    "roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9240744a-dde2-429b-8e18-4a8b4c109a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of false negatives\n",
    "false_negatives = []\n",
    "print('False Negatives')\n",
    "for image, pred_class in enumerate(predicted_class):\n",
    "    if pred_class == 0:\n",
    "        if pred_class != class_labels[image]:\n",
    "            false_negatives.append(image_names[image])\n",
    "            print(f'Image {image_names[image]} predicted class \"clean\" but labeled \"dirty\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226cd0b2-e057-4f5e-b1a3-6343e385df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7321fdba-4366-4767-9c70-086a95c5207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77f7f7e-5554-4626-b66c-1557f2b83c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfnb",
   "language": "python",
   "name": "tfnb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
